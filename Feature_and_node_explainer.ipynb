{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["SK4Op7MddeQ5"],"authorship_tag":"ABX9TyMNllINFC+MozU6tINPPGZu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Imports and loading from files"],"metadata":{"id":"SK4Op7MddeQ5"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WL0wjzYpb4_h","executionInfo":{"status":"ok","timestamp":1746924324055,"user_tz":420,"elapsed":20764,"user":{"displayName":"James Mackall","userId":"00269686780610187298"}},"outputId":"87e0276c-7d52-45b8-ea84-def3657d01c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/MB_Grader\n","Collecting torch_geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.6.1\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/MB_Grader\n","\n","!pip install torch_geometric"]},{"cell_type":"code","source":["import Batched_GNN_T5 as network\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch_geometric\n","from torch_geometric.explain import Explainer, GNNExplainer\n","\n","from collections import Counter\n","from torch.utils.data import WeightedRandomSampler\n","from torch.utils.data import Dataset\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.data import Batch"],"metadata":{"id":"Nu5R8geVcGB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PICKLE IN THE TRAIN AND TEST DATA\n","with open('Training_data/X_train.pkl', 'rb') as f:\n","    X_train = pickle.load(f)\n","with open('Training_data/X_test.pkl', 'rb') as f:\n","    X_test = pickle.load(f)\n","with open('Training_data/y_train.pkl', 'rb') as f:\n","    y_train = pickle.load(f)\n","with open('Training_data/y_test.pkl', 'rb') as f:\n","    y_test = pickle.load(f)\n","\n","with open('Training_data/global_graph.pkl', 'rb') as f:\n","    global_graph = pickle.load(f)"],"metadata":{"id":"cvQ_Mb1Kda1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = network.GNNClassifier(num_classes=11, global_graph=global_graph)\n","model.load_state_dict(torch.load('Weights/gnn_T5_weights_firsttry.pth', map_location=torch.device('cpu')))\n","\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# model.to(device)\n","# print(f\"Using device: {device}\")\n","# model.eval()  # switch to evaluation mode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Oosq6_LdDEW","executionInfo":{"status":"ok","timestamp":1746924384069,"user_tz":420,"elapsed":3345,"user":{"displayName":"James Mackall","userId":"00269686780610187298"}},"outputId":"0648ef8a-d0eb-424b-f5eb-53d860e62efd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### Actual explainer"],"metadata":{"id":"GGh5mA7Mdj5E"}},{"cell_type":"code","source":["# Optional: adjust depending on your dataset and model\n","EMBED_SIZE = 32\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","model.eval()\n","\n","# Define slices based on how you built x = [coords | orientations | hold_types | positions]\n","feature_indices = {\n","    'coords':        slice(0, 2),\n","    'positions':  slice(2, 3),\n","    'hold_types':    slice(3, 8),\n","    'orientations':     slice(8, 16),\n","}\n","\n","class ExplainerAdapter(nn.Module):\n","    def __init__(self, base_model, base_data):\n","        super().__init__()\n","        self.base_model = base_model\n","        # Direct transfer of other attributes from other data\n","        self.base_data   = base_data\n","\n","    def forward(self, x, edge_index):\n","        # reconstruct the Data object your original model needs\n","        data = torch_geometric.data.Data(\n","            x          = x,\n","            edge_index = edge_index,\n","            edge_attr  = getattr(self.base_data, 'edge_attr', None),\n","            y          = self.base_data.y,\n","            batch      = getattr(self.base_data, 'batch',    None)\n","        )\n","        return self.base_model(data)\n","\n","# --- FEATURE ATTRIBUTION USING GNNEXPLAINER ---\n","def explain_graph(model, climb):\n","    climb = climb.to(device)\n","    adapter = ExplainerAdapter(model, climb)\n","\n","    explainer = Explainer(\n","        model=adapter,\n","        algorithm=GNNExplainer(epochs = 25), # model_config=model_config, epochs = 100, lr = 0.01\n","        explanation_type='model',\n","        node_mask_type='attributes', #object, attributes\n","        edge_mask_type='object',\n","        model_config=dict(\n","                mode='multiclass_classification',\n","                task_level='graph',\n","                return_type='probs',\n","            )\n","    )\n","\n","    target = climb.y.item() if hasattr(climb, 'y') else None\n","\n","    explanation = explainer(\n","        x=climb.x,\n","        edge_index=climb.edge_index,\n","        #target=target\n","    )\n","\n","    node_mask = explanation.node_mask  # [num_nodes, num_features]\n","\n","    group_scores = {\n","        k: node_mask[:, idx].sum().item()\n","        for k, idx in feature_indices.items()\n","    }\n","\n","    total = sum(group_scores.values())\n","    normalized = {k: v / total for k, v in group_scores.items()}\n","\n","    return explanation.node_mask, group_scores, normalized\n","\n","\n","# --- FEATURE MASKING ABLATION ---\n","import copy\n","\n","def mask_feature_group(x, group_slice, method=\"zero\"):\n","    x = x.clone()\n","    if method == \"zero\":\n","        x[:, group_slice] = 0\n","    elif method == \"noise\":\n","        # Comment this line to switch between modes\n","        x[:, group_slice] = torch.randn_like(x[:, group_slice]) * 0.1\n","    return x\n","\n","def run_feature_ablation(model, climb, mask_method=\"zero\"):\n","    climb = copy.deepcopy(climb).to(device)  # full clone to avoid in-place changes\n","    model.eval()\n","\n","    with torch.no_grad():\n","        original_output = model(climb)\n","        original_pred = F.softmax(original_output, dim=1)\n","        original_class = torch.argmax(original_pred, dim=1).item()\n","\n","    print(f\"\\nOriginal prediction: class={original_class}, probs={original_pred.cpu().numpy().round(3)}\")\n","\n","    scores = {}\n","    for group, sl in feature_indices.items():\n","        masked_graph = copy.deepcopy(climb)\n","        masked_graph.x = mask_feature_group(masked_graph.x, sl, method=mask_method)\n","\n","        with torch.no_grad():\n","            masked_output = model(masked_graph)\n","            masked_pred = F.softmax(masked_output, dim=1) + 1e-8  # prevent log(0)\n","            masked_class = torch.argmax(masked_pred, dim=1).item()\n","\n","        # Log prediction and class\n","        print(f\"Masked group: {group}\")\n","        print(f\"→ Masked class: {masked_class}, probs={masked_pred.cpu().numpy().round(3)}\")\n","\n","        # Use KL divergence to measure change\n","        kl_div = F.kl_div(masked_pred.log(), original_pred, reduction=\"batchmean\")\n","        scores[group] = kl_div.item()\n","\n","    return scores"],"metadata":{"id":"kADm0Ynzb6g3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Run it"],"metadata":{"id":"zpqTwTQQC390"}},{"cell_type":"code","source":["for i in range(10):\n","  #mask, group, normed = explain_graph(model, X_test[i])\n","  #print(i, X_test[i].y.item(), normed)\n","  s = run_feature_ablation(model, X_test[i])\n","  print()\n","  print(s)\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2574kyk3hwEw","executionInfo":{"status":"ok","timestamp":1746924386663,"user_tz":420,"elapsed":2563,"user":{"displayName":"James Mackall","userId":"00269686780610187298"}},"outputId":"3f6e4e84-c869-4374-c07d-4e427f9b1760"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Original prediction: class=0, probs=[[0.999 0.001 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 1, probs=[[0.409 0.508 0.083 0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: positions\n","→ Masked class: 0, probs=[[0.646 0.354 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.001 0.033 0.075 0.    0.    0.89  0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.    0.054 0.002 0.    0.944 0.    0.    0.   ]]\n","\n","{'coords': 0.8865851759910583, 'positions': 0.4305455982685089, 'hold_types': 7.288563251495361, 'orientations': 18.403623580932617}\n","\n","\n","Original prediction: class=3, probs=[[0.003 0.016 0.04  0.932 0.009 0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 4, probs=[[0.009 0.035 0.3   0.148 0.382 0.122 0.001 0.001 0.001 0.001 0.   ]]\n","Masked group: positions\n","→ Masked class: 2, probs=[[0.015 0.08  0.414 0.215 0.261 0.01  0.002 0.002 0.001 0.001 0.001]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.007 0.099 0.196 0.005 0.004 0.689 0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.004 0.198 0.021 0.004 0.772 0.    0.    0.   ]]\n","\n","{'coords': 1.5865156650543213, 'positions': 1.214820384979248, 'hold_types': 4.728408336639404, 'orientations': 5.388124465942383}\n","\n","\n","Original prediction: class=2, probs=[[0.01  0.038 0.951 0.002 0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 2, probs=[[0.001 0.004 0.982 0.    0.013 0.    0.    0.    0.    0.    0.   ]]\n","Masked group: positions\n","→ Masked class: 3, probs=[[0.003 0.023 0.279 0.66  0.028 0.007 0.    0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.004 0.078 0.159 0.003 0.001 0.756 0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.002 0.147 0.012 0.002 0.837 0.    0.    0.   ]]\n","\n","{'coords': 0.08120626211166382, 'positions': 1.183645248413086, 'hold_types': 1.6824923753738403, 'orientations': 9.183517456054688}\n","\n","\n","Original prediction: class=0, probs=[[0.952 0.048 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 2, probs=[[0.092 0.185 0.717 0.    0.006 0.    0.    0.    0.    0.    0.   ]]\n","Masked group: positions\n","→ Masked class: 1, probs=[[0.245 0.744 0.003 0.008 0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.007 0.099 0.196 0.005 0.004 0.689 0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.004 0.198 0.021 0.004 0.772 0.    0.    0.   ]]\n","\n","{'coords': 2.161076068878174, 'positions': 1.1591010093688965, 'hold_types': 4.685848712921143, 'orientations': 14.011130332946777}\n","\n","\n","Original prediction: class=2, probs=[[0.115 0.436 0.444 0.006 0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 5, probs=[[0.001 0.012 0.107 0.065 0.31  0.423 0.012 0.    0.    0.069 0.   ]]\n","Masked group: positions\n","→ Masked class: 2, probs=[[0.007 0.022 0.965 0.001 0.005 0.001 0.    0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.007 0.099 0.196 0.005 0.004 0.689 0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.004 0.198 0.021 0.004 0.772 0.    0.    0.   ]]\n","\n","{'coords': 2.790618419647217, 'positions': 1.286601185798645, 'hold_types': 1.3335219621658325, 'orientations': 8.739665031433105}\n","\n","\n","Original prediction: class=0, probs=[[0.706 0.293 0.001 0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 1, probs=[[0.118 0.742 0.109 0.001 0.031 0.    0.    0.    0.    0.    0.   ]]\n","Masked group: positions\n","→ Masked class: 1, probs=[[0.332 0.663 0.005 0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.004 0.078 0.159 0.003 0.001 0.756 0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.002 0.147 0.012 0.002 0.837 0.    0.    0.   ]]\n","\n","{'coords': 0.9867812991142273, 'positions': 0.29189419746398926, 'hold_types': 4.0567851066589355, 'orientations': 14.536941528320312}\n","\n","\n","Original prediction: class=2, probs=[[0.004 0.006 0.989 0.    0.001 0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 4, probs=[[0.    0.001 0.046 0.105 0.846 0.001 0.    0.    0.    0.    0.   ]]\n","Masked group: positions\n","→ Masked class: 1, probs=[[0.042 0.307 0.232 0.016 0.171 0.228 0.005 0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.007 0.099 0.196 0.005 0.004 0.689 0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.004 0.198 0.021 0.004 0.772 0.    0.    0.   ]]\n","\n","{'coords': 3.0502207279205322, 'positions': 1.3986965417861938, 'hold_types': 1.581054449081421, 'orientations': 7.879628658294678}\n","\n","\n","Original prediction: class=0, probs=[[0.917 0.083 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 2, probs=[[0.003 0.026 0.946 0.    0.025 0.    0.    0.    0.    0.    0.   ]]\n","Masked group: positions\n","→ Masked class: 1, probs=[[0.146 0.78  0.071 0.003 0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.002 0.059 0.126 0.001 0.001 0.811 0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.001 0.107 0.007 0.001 0.885 0.    0.    0.   ]]\n","\n","{'coords': 5.271040916442871, 'positions': 1.4973584413528442, 'hold_types': 5.560347557067871, 'orientations': 17.25942611694336}\n","\n","\n","Original prediction: class=0, probs=[[0.998 0.002 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 0, probs=[[0.759 0.241 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: positions\n","→ Masked class: 1, probs=[[0.262 0.738 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.001 0.033 0.075 0.    0.    0.89  0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.    0.054 0.002 0.    0.944 0.    0.    0.   ]]\n","\n","{'coords': 0.2637753188610077, 'positions': 1.321885585784912, 'hold_types': 7.276834011077881, 'orientations': 18.394596099853516}\n","\n","\n","Original prediction: class=7, probs=[[0.    0.    0.001 0.    0.    0.    0.    0.999 0.    0.    0.   ]]\n","Masked group: coords\n","→ Masked class: 4, probs=[[0.    0.002 0.03  0.038 0.913 0.003 0.001 0.012 0.    0.    0.   ]]\n","Masked group: positions\n","→ Masked class: 4, probs=[[0.    0.001 0.008 0.01  0.98  0.    0.    0.    0.    0.    0.   ]]\n","Masked group: hold_types\n","→ Masked class: 5, probs=[[0.007 0.099 0.196 0.005 0.004 0.689 0.    0.    0.    0.    0.   ]]\n","Masked group: orientations\n","→ Masked class: 7, probs=[[0.    0.    0.    0.004 0.198 0.021 0.004 0.772 0.    0.    0.   ]]\n","\n","{'coords': 4.418403625488281, 'positions': 11.678436279296875, 'hold_types': 11.850200653076172, 'orientations': 0.2574315071105957}\n","\n"]}]},{"cell_type":"code","source":["for i in range(10):\n","  mask, group, normed = explain_graph(model, X_test[i])\n","  print(i, X_test[i].y.item(), normed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57zvtUFy_D1R","executionInfo":{"status":"ok","timestamp":1746924433824,"user_tz":420,"elapsed":47159,"user":{"displayName":"James Mackall","userId":"00269686780610187298"}},"outputId":"02f9d430-33c5-4b00-9395-d7aa26581679"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 0 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.5278516594497401, 'orientations': 0.4721483405502599}\n","1 3 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.5465827458557185, 'orientations': 0.45341725414428147}\n","2 4 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.36506771461023285, 'orientations': 0.6349322853897671}\n","3 0 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.6261906641345216, 'orientations': 0.3738093358654783}\n","4 4 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.5272980756458483, 'orientations': 0.47270192435415165}\n","5 0 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.4912918684357621, 'orientations': 0.5087081315642379}\n","6 2 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.6254861848644986, 'orientations': 0.3745138151355014}\n","7 0 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.5155877687695005, 'orientations': 0.48441223123049953}\n","8 0 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.47805017520728565, 'orientations': 0.5219498247927143}\n","9 6 {'coords': 0.0, 'positions': 0.0, 'hold_types': 0.41960703653497594, 'orientations': 0.580392963465024}\n"]}]},{"cell_type":"markdown","source":["### other"],"metadata":{"id":"gCgRwcZtC9L8"}},{"cell_type":"code","source":["### NEXT STEP IS TO IDENTIFY WHAT THE WEIGHTS OF EVERY HOLD / SLICE ACTUALLY ARE AND ESSENTIALLY WHERE THIS NON-USE OF COORDS+ORIENTATIONS IS HAPPENNING"],"metadata":{"id":"srlFUCMv7Tbx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from captum.attr import IntegratedGradients\n","# from captum.attr import visualization as viz\n","\n","# ig = IntegratedGradients(model)\n","# attributions = ig.attribute(inputs=(X_test[69]),\n","#                             target=Y_test[69],\n","#                             n_steps=50)\n","\n","# # attributions[0] is feature‐wise importance for each node\n","# fig, ax = viz.visualize_feature_importances(\n","#     attributions[0].cpu().detach().numpy(),\n","#     feature_names=[f\"f{i}\" for i in range(x.size(1))]\n","# )"],"metadata":{"id":"rtTvPbooiUYX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#group"],"metadata":{"id":"_b-vOO9j4E3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mask.shape, X_test[69].x.shape\n","\n","# for x, m in zip(X_test[69].x, mask):\n","#   print(x)\n","#   print(m)\n","#   print()"],"metadata":{"id":"_yTv8Olj2Y1r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"TwHiVQ6a1GmH","executionInfo":{"status":"error","timestamp":1746924433864,"user_tz":420,"elapsed":40,"user":{"displayName":"James Mackall","userId":"00269686780610187298"}},"outputId":"d59d3cf2-b668-4ff8-ad85-23672a6cf37a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"No active exception to reraise","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-9c9a2cba73bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"]}]},{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","class FeatureActivationLogger:\n","    def __init__(self, model, device='cpu', verbose=True, plot_histograms=False):\n","        self.model = model.to(device)\n","        self.device = device\n","        self.verbose = verbose\n","        self.plot_histograms = plot_histograms\n","\n","        self.reset()\n","\n","    def reset(self):\n","        self.all_stats = {\n","            'coords': [],\n","            'positions': [],\n","            'hold_types': [],\n","            'orientations': []\n","        }\n","\n","    def analyze_one_climb(self, climb_data):\n","        self.model.eval()\n","        climb_data = climb_data.to(self.device)\n","\n","        with torch.no_grad():\n","            # Step 1: Forward up to feature embeddings\n","            x = climb_data.x\n","            coords_y = x[:, 0].to(torch.long)\n","            coords_x = x[:, 1].to(torch.long)\n","            coords_y = self.model.coordinate_embedding_y(coords_y)\n","            coords_x = self.model.coordinate_embedding_x(coords_x)\n","            coords   = torch.cat([coords_y, coords_x], dim=1)\n","            coords   = self.model.coordinate_smoosh(coords)\n","            coords   = F.leaky_relu(coords)\n","\n","            positions = x[:, 2].to(torch.long)\n","            positions = self.model.position_embedding_1(positions)\n","            positions = F.leaky_relu(positions)\n","            #positions = self.model.position_embedding_2(positions)\n","\n","            hold_types = x[:, 3:8]\n","            hold_types_sum = hold_types.sum(dim=1, keepdim=True)\n","            hold_types = self.model.hold_type_one_hot_embedding(hold_types)\n","            hold_types = hold_types / (hold_types_sum + self.model.epsilon)\n","\n","            orientations = x[:, 8:16]\n","            orientations_sum = orientations.sum(dim=1, keepdim=True)\n","            orientations = self.model.orientation_one_hot_embedding(orientations)\n","            orientations = orientations / (orientations_sum + self.model.epsilon)\n","\n","            # Step 2: Calculate stats\n","            stats = {}\n","            for group_name, tensor in zip(\n","                ['coords', 'positions', 'hold_types', 'orientations'],\n","                [coords, positions, hold_types, orientations]\n","            ):\n","                mean_abs = tensor.abs().mean().item()\n","                zero_fraction = (tensor == 0).float().mean().item()\n","\n","                stats[group_name] = {\n","                    'mean_abs': mean_abs,\n","                    'zero_fraction': zero_fraction\n","                }\n","\n","                # Save to overall stats\n","                self.all_stats[group_name].append(stats[group_name])\n","\n","                if self.verbose:\n","                    print(f\"--- {group_name} ---\")\n","                    print(f\"Mean absolute value: {mean_abs:.6f}\")\n","                    print(f\"Fraction zeros: {zero_fraction:.4f}\")\n","\n","                if self.plot_histograms:\n","                    plt.hist(tensor.cpu().numpy().flatten(), bins=30)\n","                    plt.title(f\"{group_name} activation histogram\")\n","                    plt.xlabel(\"Value\")\n","                    plt.ylabel(\"Frequency\")\n","                    plt.show()\n","\n","    def summarize(self):\n","        print(\"\\n\\n==== Summary across all climbs ====\")\n","        for group_name in self.all_stats.keys():\n","            mean_abs_values = [x['mean_abs'] for x in self.all_stats[group_name]]\n","            zero_fractions  = [x['zero_fraction'] for x in self.all_stats[group_name]]\n","\n","            print(f\"\\nFeature Group: {group_name}\")\n","            print(f\"Avg Mean Absolute Activation: {np.mean(mean_abs_values):.6f}\")\n","            print(f\"Avg Zero Fraction: {np.mean(zero_fractions):.4f}\")"],"metadata":{"id":"INVf9cK5IX8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logger = FeatureActivationLogger(model, device=device, verbose=True, plot_histograms=False)\n","\n","for i in range(5):  # Assuming X_test is a list of Data objects\n","    logger.analyze_one_climb(X_test[i])\n","    print()\n","\n","# After analyzing many climbs:\n","logger.summarize()"],"metadata":{"id":"UB59gOCxIY5p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raise"],"metadata":{"id":"GJzEsLAkXf3M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(torch_geometric.__version__)"],"metadata":{"id":"6GjUzbvfh5XI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ExplainerAdapter(nn.Module):\n","    def __init__(self, base_model, base_data):\n","        super().__init__()\n","        self.base_model = base_model\n","        # Direct transfer of other attributes from other data\n","        self.base_data   = base_data\n","\n","    def forward(self, x, edge_index):\n","        # reconstruct the Data object your original model needs\n","        data = torch_geometric.data.Data(\n","            x          = x,\n","            edge_index = edge_index,\n","            edge_attr  = getattr(self.base_data, 'edge_attr', None),\n","            y          = self.base_data.y,\n","            batch      = getattr(self.base_data, 'batch',    None)\n","        )\n","        return self.base_model(data)\n","\n","# Instantiate it\n","adapter = ExplainerAdapter(model, X_test[0])"],"metadata":{"id":"z5pKrFcWoOIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["climb = X_test[0]\n","\n","explainer = Explainer(\n","        model=adapter,\n","        algorithm=GNNExplainer(),\n","        explanation_type='model',\n","        node_mask_type='attributes',\n","        edge_mask_type='object',\n","        model_config=dict(\n","                mode='multiclass_classification',\n","                task_level='graph',\n","                return_type='probs',\n","            )\n","    )\n","\n","explanation = explainer(\n","        x=climb.x,\n","        edge_index=climb.edge_index,\n","        #target=target\n","    )\n","\n"],"metadata":{"id":"qDkwn2OZkQpR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["node_mask = explanation.node_mask  # [num_nodes, num_features]\n","\n","group_scores = {\n","    k: node_mask[:, idx].sum().item()\n","    for k, idx in feature_indices.items()\n","}\n","\n","total = sum(group_scores.values())\n","normalized = {k: v / total for k, v in group_scores.items()}"],"metadata":{"id":"oyaEBAJtzXcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["normalized"],"metadata":{"id":"p-3O-NmtzjqV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test[0]"],"metadata":{"id":"pCFwBq5ayWiU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R5zO9KNMyX5L"},"execution_count":null,"outputs":[]}]}